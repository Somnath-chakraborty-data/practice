{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "928433ef",
   "metadata": {},
   "source": [
    "PySpark Practice - Complete Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb30527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117789df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark Version: 4.0.1\n",
      "‚úÖ Spark Master: local[*]\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark Practice\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to reduce noise\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\"‚úÖ Spark Version: {spark.version}\")\n",
    "print(f\"‚úÖ Spark Master: {spark.sparkContext.master}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "140fcfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Sample DataFrame:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----------+------+\n",
      "|   name|age| department|salary|\n",
      "+-------+---+-----------+------+\n",
      "|  Alice| 25|Engineering| 75000|\n",
      "|    Bob| 30|  Marketing| 65000|\n",
      "|Charlie| 35|Engineering| 85000|\n",
      "|  Diana| 28|         HR| 60000|\n",
      "|    Eve| 32|Engineering| 90000|\n",
      "|  Frank| 29|  Marketing| 70000|\n",
      "+-------+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 2. Create Sample DataFrames\n",
    "# ============================================\n",
    "\n",
    "# Method 1: From Python list\n",
    "data = [\n",
    "    (\"Alice\", 25, \"Engineering\", 75000),\n",
    "    (\"Bob\", 30, \"Marketing\", 65000),\n",
    "    (\"Charlie\", 35, \"Engineering\", 85000),\n",
    "    (\"Diana\", 28, \"HR\", 60000),\n",
    "    (\"Eve\", 32, \"Engineering\", 90000),\n",
    "    (\"Frank\", 29, \"Marketing\", 70000)\n",
    "]\n",
    "\n",
    "columns = [\"name\", \"age\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "print(\"\\nüìä Sample DataFrame:\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "216601b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Select specific columns:\n",
      "+-------+------+\n",
      "|   name|salary|\n",
      "+-------+------+\n",
      "|  Alice| 75000|\n",
      "|    Bob| 65000|\n",
      "|Charlie| 85000|\n",
      "|  Diana| 60000|\n",
      "|    Eve| 90000|\n",
      "|  Frank| 70000|\n",
      "+-------+------+\n",
      "\n",
      "\n",
      "üîπ Filter: Salary > 70000\n",
      "+-------+---+-----------+------+\n",
      "|   name|age| department|salary|\n",
      "+-------+---+-----------+------+\n",
      "|  Alice| 25|Engineering| 75000|\n",
      "|Charlie| 35|Engineering| 85000|\n",
      "|    Eve| 32|Engineering| 90000|\n",
      "+-------+---+-----------+------+\n",
      "\n",
      "\n",
      "üîπ Add bonus column (10% of salary):\n",
      "+-------+---+-----------+------+------+\n",
      "|   name|age| department|salary| bonus|\n",
      "+-------+---+-----------+------+------+\n",
      "|  Alice| 25|Engineering| 75000|7500.0|\n",
      "|    Bob| 30|  Marketing| 65000|6500.0|\n",
      "|Charlie| 35|Engineering| 85000|8500.0|\n",
      "|  Diana| 28|         HR| 60000|6000.0|\n",
      "|    Eve| 32|Engineering| 90000|9000.0|\n",
      "|  Frank| 29|  Marketing| 70000|7000.0|\n",
      "+-------+---+-----------+------+------+\n",
      "\n",
      "\n",
      "üîπ Rename column:\n",
      "+-------------+---+-----------+------+\n",
      "|employee_name|age| department|salary|\n",
      "+-------------+---+-----------+------+\n",
      "|        Alice| 25|Engineering| 75000|\n",
      "|          Bob| 30|  Marketing| 65000|\n",
      "|      Charlie| 35|Engineering| 85000|\n",
      "|        Diana| 28|         HR| 60000|\n",
      "|          Eve| 32|Engineering| 90000|\n",
      "+-------------+---+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "üîπ Drop age column:\n",
      "+-------+-----------+------+\n",
      "|   name| department|salary|\n",
      "+-------+-----------+------+\n",
      "|  Alice|Engineering| 75000|\n",
      "|    Bob|  Marketing| 65000|\n",
      "|Charlie|Engineering| 85000|\n",
      "|  Diana|         HR| 60000|\n",
      "|    Eve|Engineering| 90000|\n",
      "|  Frank|  Marketing| 70000|\n",
      "+-------+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3. Basic DataFrame Operations\n",
    "# ============================================\n",
    "\n",
    "# Select columns\n",
    "print(\"\\nüîπ Select specific columns:\")\n",
    "df.select(\"name\", \"salary\").show()\n",
    "\n",
    "# Filter rows\n",
    "print(\"\\nüîπ Filter: Salary > 70000\")\n",
    "df.filter(df.salary > 70000).show()\n",
    "\n",
    "# Add new column\n",
    "print(\"\\nüîπ Add bonus column (10% of salary):\")\n",
    "df.withColumn(\"bonus\", df.salary * 0.1).show()\n",
    "\n",
    "# Rename column\n",
    "print(\"\\nüîπ Rename column:\")\n",
    "df.withColumnRenamed(\"name\", \"employee_name\").show(5)\n",
    "\n",
    "# Drop column\n",
    "print(\"\\nüîπ Drop age column:\")\n",
    "df.drop(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7d36661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Aggregations:\n",
      "Total employees: 6\n",
      "\n",
      "üîπ Average salary by department:\n",
      "+-----------+-----------------+--------------+\n",
      "| department|       avg_salary|employee_count|\n",
      "+-----------+-----------------+--------------+\n",
      "|Engineering|83333.33333333333|             3|\n",
      "|  Marketing|          67500.0|             2|\n",
      "|         HR|          60000.0|             1|\n",
      "+-----------+-----------------+--------------+\n",
      "\n",
      "\n",
      "üîπ Department statistics:\n",
      "+-----------+-----------------+----------+----------+-----+\n",
      "| department|       avg_salary|min_salary|max_salary|count|\n",
      "+-----------+-----------------+----------+----------+-----+\n",
      "|Engineering|83333.33333333333|     75000|     90000|    3|\n",
      "|  Marketing|          67500.0|     65000|     70000|    2|\n",
      "|         HR|          60000.0|     60000|     60000|    1|\n",
      "+-----------+-----------------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4. Aggregations\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüìà Aggregations:\")\n",
    "\n",
    "# Count\n",
    "print(f\"Total employees: {df.count()}\")\n",
    "\n",
    "# Group by and aggregate\n",
    "print(\"\\nüîπ Average salary by department:\")\n",
    "df.groupBy(\"department\").agg(\n",
    "    avg(\"salary\").alias(\"avg_salary\"),\n",
    "    count(\"*\").alias(\"employee_count\")\n",
    ").show()\n",
    "\n",
    "# Multiple aggregations\n",
    "print(\"\\nüîπ Department statistics:\")\n",
    "df.groupBy(\"department\").agg(\n",
    "    avg(\"salary\").alias(\"avg_salary\"),\n",
    "    min(\"salary\").alias(\"min_salary\"),\n",
    "    max(\"salary\").alias(\"max_salary\"),\n",
    "    count(\"*\").alias(\"count\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "514917dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Sort by salary (descending):\n",
      "+-------+---+-----------+------+\n",
      "|   name|age| department|salary|\n",
      "+-------+---+-----------+------+\n",
      "|    Eve| 32|Engineering| 90000|\n",
      "|Charlie| 35|Engineering| 85000|\n",
      "|  Alice| 25|Engineering| 75000|\n",
      "|  Frank| 29|  Marketing| 70000|\n",
      "|    Bob| 30|  Marketing| 65000|\n",
      "|  Diana| 28|         HR| 60000|\n",
      "+-------+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 5. Sorting\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüîπ Sort by salary (descending):\")\n",
    "df.orderBy(col(\"salary\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "492291eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ SQL Query:\n",
      "+-----------+----------+---------+\n",
      "| department|avg_salary|emp_count|\n",
      "+-----------+----------+---------+\n",
      "|Engineering|   87500.0|        2|\n",
      "|  Marketing|   67500.0|        2|\n",
      "|         HR|   60000.0|        1|\n",
      "+-----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register as temp view\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "print(\"\\nüîπ SQL Query:\")\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        department,\n",
    "        AVG(salary) as avg_salary,\n",
    "        COUNT(*) as emp_count\n",
    "    FROM employees\n",
    "    WHERE age >= 28\n",
    "    GROUP BY department\n",
    "    ORDER BY avg_salary DESC\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6e10490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Date operations:\n",
      "+----------+------+----+-----+---+\n",
      "|      date|amount|year|month|day|\n",
      "+----------+------+----+-----+---+\n",
      "|2024-01-15|  1000|2024|    1| 15|\n",
      "|2024-02-20|  1500|2024|    2| 20|\n",
      "|2024-03-10|  2000|2024|    3| 10|\n",
      "|2024-04-05|  1200|2024|    4|  5|\n",
      "+----------+------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 7. Working with Dates\n",
    "# ============================================\n",
    "\n",
    "date_data = [\n",
    "    (\"2024-01-15\", 1000),\n",
    "    (\"2024-02-20\", 1500),\n",
    "    (\"2024-03-10\", 2000),\n",
    "    (\"2024-04-05\", 1200)\n",
    "]\n",
    "\n",
    "df_dates = spark.createDataFrame(date_data, [\"date\", \"amount\"])\n",
    "\n",
    "print(\"\\nüìÖ Date operations:\")\n",
    "df_dates = df_dates.withColumn(\"date\", to_date(col(\"date\")))\n",
    "df_dates = df_dates.withColumn(\"year\", year(\"date\"))\n",
    "df_dates = df_dates.withColumn(\"month\", month(\"date\"))\n",
    "df_dates = df_dates.withColumn(\"day\", dayofmonth(\"date\"))\n",
    "df_dates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f72f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ String operations:\n",
      "+-------+---+-----------+------+----------+-----------+-----------+\n",
      "|   name|age| department|salary|name_upper|name_length|name_substr|\n",
      "+-------+---+-----------+------+----------+-----------+-----------+\n",
      "|  Alice| 25|Engineering| 75000|     ALICE|          5|         Al|\n",
      "|    Bob| 30|  Marketing| 65000|       BOB|          3|         Bo|\n",
      "|Charlie| 35|Engineering| 85000|   CHARLIE|          7|         Ch|\n",
      "|  Diana| 28|         HR| 60000|     DIANA|          5|         Di|\n",
      "|    Eve| 32|Engineering| 90000|       EVE|          3|         Ev|\n",
      "|  Frank| 29|  Marketing| 70000|     FRANK|          5|         Fr|\n",
      "+-------+---+-----------+------+----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 8. String Operations\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüîπ String operations:\")\n",
    "df.withColumn(\"name_upper\", upper(\"name\")) \\\n",
    "  .withColumn(\"name_length\", length(\"name\")) \\\n",
    "  .withColumn(\"name_substr\", substring(\"name\", 1, 2)) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e590f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì DataFrame with nulls:\n",
      "+----+----+------+\n",
      "|name| age|salary|\n",
      "+----+----+------+\n",
      "|John|  25| 50000|\n",
      "|Jane|NULL| 60000|\n",
      "| Bob|  30|  NULL|\n",
      "|NULL|  28| 55000|\n",
      "+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 9. Handling Nulls\n",
    "# ============================================\n",
    "\n",
    "null_data = [\n",
    "    (\"John\", 25, 50000),\n",
    "    (\"Jane\", None, 60000),\n",
    "    (\"Bob\", 30, None),\n",
    "    (None, 28, 55000)\n",
    "]\n",
    "\n",
    "df_nulls = spark.createDataFrame(null_data, [\"name\", \"age\", \"salary\"])\n",
    "\n",
    "print(\"\\n‚ùì DataFrame with nulls:\")\n",
    "df_nulls.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c075a520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Drop rows with any null:\n",
      "+----+---+------+\n",
      "|name|age|salary|\n",
      "+----+---+------+\n",
      "|John| 25| 50000|\n",
      "+----+---+------+\n",
      "\n",
      "\n",
      "üîπ Fill nulls:\n",
      "+-------+---+------+\n",
      "|   name|age|salary|\n",
      "+-------+---+------+\n",
      "|   John| 25| 50000|\n",
      "|   Jane|  0| 60000|\n",
      "|    Bob| 30|     0|\n",
      "|Unknown| 28| 55000|\n",
      "+-------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop nulls\n",
    "print(\"\\nüîπ Drop rows with any null:\")\n",
    "df_nulls.dropna().show()\n",
    "\n",
    "# Fill nulls\n",
    "print(\"\\nüîπ Fill nulls:\")\n",
    "df_nulls.fillna({\"age\": 0, \"salary\": 0, \"name\": \"Unknown\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0623e64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó Join example:\n",
      "+-----------+-------+---+------+----------+\n",
      "| department|   name|age|salary|  location|\n",
      "+-----------+-------+---+------+----------+\n",
      "|Engineering|  Alice| 25| 75000|Building A|\n",
      "|Engineering|Charlie| 35| 85000|Building A|\n",
      "|Engineering|    Eve| 32| 90000|Building A|\n",
      "|         HR|  Diana| 28| 60000|Building C|\n",
      "|  Marketing|    Bob| 30| 65000|Building B|\n",
      "|  Marketing|  Frank| 29| 70000|Building B|\n",
      "+-----------+-------+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 10. Joins\n",
    "# ============================================\n",
    "\n",
    "# Create second dataframe\n",
    "dept_data = [\n",
    "    (\"Engineering\", \"Building A\"),\n",
    "    (\"Marketing\", \"Building B\"),\n",
    "    (\"HR\", \"Building C\")\n",
    "]\n",
    "\n",
    "df_dept = spark.createDataFrame(dept_data, [\"department\", \"location\"])\n",
    "\n",
    "print(\"\\nüîó Join example:\")\n",
    "df.join(df_dept, on=\"department\", how=\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d1d0190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü™ü Window functions:\n",
      "+-------+---+-----------+------+----+----------+----------+\n",
      "|   name|age| department|salary|rank|dense_rank|row_number|\n",
      "+-------+---+-----------+------+----+----------+----------+\n",
      "|    Eve| 32|Engineering| 90000|   1|         1|         1|\n",
      "|Charlie| 35|Engineering| 85000|   2|         2|         2|\n",
      "|  Alice| 25|Engineering| 75000|   3|         3|         3|\n",
      "|  Diana| 28|         HR| 60000|   1|         1|         1|\n",
      "|  Frank| 29|  Marketing| 70000|   1|         1|         1|\n",
      "|    Bob| 30|  Marketing| 65000|   2|         2|         2|\n",
      "+-------+---+-----------+------+----+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 11. Window Functions\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nü™ü Window functions:\")\n",
    "\n",
    "# Rank employees by salary within department\n",
    "window_spec = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
    "\n",
    "df.withColumn(\"rank\", rank().over(window_spec)) \\\n",
    "  .withColumn(\"dense_rank\", dense_rank().over(window_spec)) \\\n",
    "  .withColumn(\"row_number\", row_number().over(window_spec)) \\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b414471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß UDF example:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----------+------+---------------+\n",
      "|   name|age| department|salary|salary_category|\n",
      "+-------+---+-----------+------+---------------+\n",
      "|  Alice| 25|Engineering| 75000|         Medium|\n",
      "|    Bob| 30|  Marketing| 65000|         Medium|\n",
      "|Charlie| 35|Engineering| 85000|           High|\n",
      "|  Diana| 28|         HR| 60000|            Low|\n",
      "|    Eve| 32|Engineering| 90000|           High|\n",
      "|  Frank| 29|  Marketing| 70000|         Medium|\n",
      "+-------+---+-----------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 12. User Defined Functions (UDF)\n",
    "# ============================================\n",
    "\n",
    "# Define UDF\n",
    "def categorize_salary(salary):\n",
    "    if salary >= 80000:\n",
    "        return \"High\"\n",
    "    elif salary >= 65000:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "categorize_udf = udf(categorize_salary, StringType())\n",
    "\n",
    "print(\"\\nüîß UDF example:\")\n",
    "df.withColumn(\"salary_category\", categorize_udf(\"salary\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ce0463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Writing to CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV written to /home/somnath/coding/pyspark/output/employees_csv/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 13. Reading and Writing Data\n",
    "# ============================================\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"/home/somnath/coding/pyspark/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Write to CSV\n",
    "print(\"\\nüíæ Writing to CSV...\")\n",
    "df.coalesce(1).write.mode(\"overwrite\").csv(\n",
    "    f\"file://{output_dir}/employees_csv\", \n",
    "    header=True\n",
    ")\n",
    "print(f\"‚úÖ CSV written to {output_dir}/employees_csv/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cdc0e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ Reading from CSV...\n",
      "+-------+---+-----------+------+\n",
      "|   name|age| department|salary|\n",
      "+-------+---+-----------+------+\n",
      "|  Alice| 25|Engineering| 75000|\n",
      "|    Bob| 30|  Marketing| 65000|\n",
      "|Charlie| 35|Engineering| 85000|\n",
      "|  Diana| 28|         HR| 60000|\n",
      "|    Eve| 32|Engineering| 90000|\n",
      "|  Frank| 29|  Marketing| 70000|\n",
      "+-------+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read from CSV\n",
    "print(\"\\nüìñ Reading from CSV...\")\n",
    "df_read = spark.read.csv(\n",
    "    f\"file://{output_dir}/employees_csv\", \n",
    "    header=True, \n",
    "    inferSchema=True\n",
    ")\n",
    "df_read.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0089089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Writing to Parquet...\n",
      "‚úÖ Parquet written to /home/somnath/coding/pyspark/output/employees_parquet/\n"
     ]
    }
   ],
   "source": [
    "# Write to Parquet\n",
    "print(\"\\nüíæ Writing to Parquet...\")\n",
    "df.write.mode(\"overwrite\").parquet(f\"file://{output_dir}/employees_parquet\")\n",
    "print(f\"‚úÖ Parquet written to {output_dir}/employees_parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b80195d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìñ Reading from Parquet...\n",
      "+-------+---+-----------+------+\n",
      "|   name|age| department|salary|\n",
      "+-------+---+-----------+------+\n",
      "|Charlie| 35|Engineering| 85000|\n",
      "|  Alice| 25|Engineering| 75000|\n",
      "|  Frank| 29|  Marketing| 70000|\n",
      "|    Eve| 32|Engineering| 90000|\n",
      "|    Bob| 30|  Marketing| 65000|\n",
      "|  Diana| 28|         HR| 60000|\n",
      "+-------+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read from Parquet\n",
    "print(\"\\nüìñ Reading from Parquet...\")\n",
    "df_parquet = spark.read.parquet(f\"file://{output_dir}/employees_parquet\")\n",
    "df_parquet.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f52c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Writing to JSON...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ JSON written to /home/somnath/coding/pyspark/output/employees_json/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write to JSON\n",
    "print(\"\\nüíæ Writing to JSON...\")\n",
    "df.coalesce(1).write.mode(\"overwrite\").json(f\"file://{output_dir}/employees_json\")\n",
    "print(f\"‚úÖ JSON written to {output_dir}/employees_json/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07edeed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° DataFrame cached\n",
      "\n",
      "üìã Execution Plan:\n",
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(salary#1424L) AND (salary#1424L > 70000))\n",
      "+- InMemoryTableScan [name#1421, age#1422L, department#1423, salary#1424L], [isnotnull(salary#1424L), (salary#1424L > 70000)]\n",
      "      +- InMemoryRelation [name#1421, age#1422L, department#1423, salary#1424L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *(1) Scan ExistingRDD[name#1421,age#1422L,department#1423,salary#1424L]\n",
      "\n",
      "\n",
      "Partitions: 3\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 14. Performance Optimization\n",
    "# ============================================\n",
    "\n",
    "# Cache DataFrame\n",
    "df.cache()\n",
    "print(\"\\n‚ö° DataFrame cached\")\n",
    "\n",
    "# Show execution plan\n",
    "print(\"\\nüìã Execution Plan:\")\n",
    "df.filter(df.salary > 70000).explain()\n",
    "\n",
    "# Repartition\n",
    "df_repart = df.repartition(3)\n",
    "print(f\"Partitions: {df_repart.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f492c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Statistics:\n",
      "+-------+-----+------------------+-----------+------------------+\n",
      "|summary| name|               age| department|            salary|\n",
      "+-------+-----+------------------+-----------+------------------+\n",
      "|  count|    6|                 6|          6|                 6|\n",
      "|   mean| NULL|29.833333333333332|       NULL| 74166.66666666667|\n",
      "| stddev| NULL| 3.430257521916783|       NULL|11583.033569262703|\n",
      "|    min|Alice|                25|Engineering|             60000|\n",
      "|    max|Frank|                35|  Marketing|             90000|\n",
      "+-------+-----+------------------+-----------+------------------+\n",
      "\n",
      "+-----------------+------------------+----------+----------+\n",
      "|       avg_salary|        std_salary|min_salary|max_salary|\n",
      "+-----------------+------------------+----------+----------+\n",
      "|74166.66666666667|11583.033569262703|     60000|     90000|\n",
      "+-----------------+------------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 15. Statistics\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüìä Statistics:\")\n",
    "df.describe().show()\n",
    "\n",
    "# Specific stats\n",
    "df.select(\n",
    "    mean(\"salary\").alias(\"avg_salary\"),\n",
    "    stddev(\"salary\").alias(\"std_salary\"),\n",
    "    min(\"salary\").alias(\"min_salary\"),\n",
    "    max(\"salary\").alias(\"max_salary\")\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cda72143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üêº Convert to Pandas:\n",
      "Type: <class 'pandas.core.frame.DataFrame'>\n",
      "      name  age   department  salary\n",
      "0    Alice   25  Engineering   75000\n",
      "1      Bob   30    Marketing   65000\n",
      "2  Charlie   35  Engineering   85000\n",
      "3    Diana   28           HR   60000\n",
      "4      Eve   32  Engineering   90000\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 16. Convert to/from Pandas\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüêº Convert to Pandas:\")\n",
    "pandas_df = df.toPandas()\n",
    "print(f\"Type: {type(pandas_df)}\")\n",
    "print(pandas_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2624c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Convert back to Spark:\n",
      "+-------+---+-----------+------+\n",
      "|   name|age| department|salary|\n",
      "+-------+---+-----------+------+\n",
      "|  Alice| 25|Engineering| 75000|\n",
      "|    Bob| 30|  Marketing| 65000|\n",
      "|Charlie| 35|Engineering| 85000|\n",
      "|  Diana| 28|         HR| 60000|\n",
      "|    Eve| 32|Engineering| 90000|\n",
      "|  Frank| 29|  Marketing| 70000|\n",
      "+-------+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert from Pandas\n",
    "print(\"\\nüîÑ Convert back to Spark:\")\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5995a4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Distinct values in department:\n",
      "+-----------+\n",
      "| department|\n",
      "+-----------+\n",
      "|Engineering|\n",
      "|  Marketing|\n",
      "|         HR|\n",
      "+-----------+\n",
      "\n",
      "\n",
      "üîπ Sample data (50%):\n",
      "+-------+---+-----------+------+\n",
      "|   name|age| department|salary|\n",
      "+-------+---+-----------+------+\n",
      "|Charlie| 35|Engineering| 85000|\n",
      "+-------+---+-----------+------+\n",
      "\n",
      "\n",
      "üîπ Column data types:\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 17. Additional Useful Operations\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüîπ Distinct values in department:\")\n",
    "df.select(\"department\").distinct().show()\n",
    "\n",
    "print(\"\\nüîπ Sample data (50%):\")\n",
    "df.sample(fraction=0.5, seed=42).show()\n",
    "\n",
    "print(\"\\nüîπ Column data types:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b37c51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ PySpark practice complete!\n",
      "\n",
      "üìÅ Output files saved in: /home/somnath/coding/pyspark/output\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 18. Clean Up\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n‚úÖ PySpark practice complete!\")\n",
    "print(f\"\\nüìÅ Output files saved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7808ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to stop Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
